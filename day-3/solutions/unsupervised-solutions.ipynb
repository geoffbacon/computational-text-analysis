{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Unsupervised methods\n",
    "\n",
    "In this lesson, we'll cover unsupervised computational text anlalysis approaches. The central methods covered are TF-IDF and Topic Modeling. Both of these are common approachs in the social sciences and humanities.\n",
    "\n",
    "[DTM/TF-IDF](#dtm)<br>\n",
    "\n",
    "[Topic modeling](#topics)<br>\n",
    "\n",
    "### Today you will\n",
    "* Understand the DTM and why it's important to text analysis\n",
    "* Learn how to create a DTM from a .csv file\n",
    "* Learn basic functionality of Python's package scikit-learn\n",
    "* Understand tf-idf scores, and word scores in general\n",
    "* Learn a simple way to identify distinctive words\n",
    "* Implement a basic topic modeling algorithm and learn how to tweak it\n",
    "* In the process, gain more familiarity and comfort with the Pandas package and manipulating data\n",
    "\n",
    "### Time\n",
    "- Teaching: 30 minutes\n",
    "- Exercises: 30 minutes\n",
    "\n",
    "\n",
    "### Key Jargon\n",
    "* *Document Term Matrix*:\n",
    "    * a matrix that describes the frequency of terms that occur in a collection of documents. In a document-term matrix, rows correspond to documents in the collection and columns correspond to terms.\n",
    "* *TF-IDF Scores*: \n",
    "    * short for term frequency–inverse document frequency, is a numerical statistic that is intended to reflect how important a word is to a document in a collection or corpus.\n",
    "* *Topic Modeling*:\n",
    "    * A general class of statistical models that uncover abstract topics within a text. It uses the co-occurrence of words within documents, compared to their distribution across documents, to uncover these abstract themes. The output is a list of weighted words, which indicate the subject of each topic, and a weight distribution across topics for each document.\n",
    "    \n",
    "* *LDA*:\n",
    "    * Latent Dirichlet Allocation. A particular model for topic modeling. It does not take document order into account, unlike other topic modeling algorithms."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## DTM/TF-IDF <a id='dtm'></a>\n",
    "\n",
    "In this lesson we will use Python's scikit-learn package learn to make a document term matrix from a .csv Music Reviews dataset (collected from MetaCritic.com). We will then use the DTM and a word weighting technique called tf-idf (term frequency inverse document frequency) to identify important and discriminating words within this dataset (utilizing the Pandas package). The illustrating question: **what words distinguish reviews of Rap albums, Indie Rock albums, and Jazz albums?**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "DATA_DIR = '../data'\n",
    "music_fname = 'music_reviews.csv'\n",
    "music_fname = os.path.join(DATA_DIR, music_fname)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### First attempt at reading in file"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "reviews = pd.read_csv(music_fname)\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Our first attempt at reading in the csv file failed. Why?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>critic</th>\n",
       "      <th>score</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Don't Panic</td>\n",
       "      <td>All Time Low</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2012-10-09 00:00:00</td>\n",
       "      <td>Kerrang!</td>\n",
       "      <td>74.0</td>\n",
       "      <td>While For Baltimore proves they can still writ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Fear and Saturday Night</td>\n",
       "      <td>Ryan Bingham</td>\n",
       "      <td>Country</td>\n",
       "      <td>2015-01-20 00:00:00</td>\n",
       "      <td>Uncut</td>\n",
       "      <td>70.0</td>\n",
       "      <td>There's nothing fake about the purgatorial nar...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>The Way I'm Livin'</td>\n",
       "      <td>Lee Ann Womack</td>\n",
       "      <td>Country</td>\n",
       "      <td>2014-09-23 00:00:00</td>\n",
       "      <td>Q Magazine</td>\n",
       "      <td>84.0</td>\n",
       "      <td>All life's disastrous lows are here on a caree...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Doris</td>\n",
       "      <td>Earl Sweatshirt</td>\n",
       "      <td>Rap</td>\n",
       "      <td>2013-08-20 00:00:00</td>\n",
       "      <td>Pitchfork</td>\n",
       "      <td>82.0</td>\n",
       "      <td>With Doris, Odd Future’s Odysseus is finally b...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Giraffe</td>\n",
       "      <td>Echoboy</td>\n",
       "      <td>Rock</td>\n",
       "      <td>2003-02-25 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>71.0</td>\n",
       "      <td>Though Giraffe is definitely Echoboy's most im...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                     album           artist     genre         release_date  \\\n",
       "0              Don't Panic     All Time Low  Pop/Rock  2012-10-09 00:00:00   \n",
       "1  Fear and Saturday Night     Ryan Bingham   Country  2015-01-20 00:00:00   \n",
       "2       The Way I'm Livin'   Lee Ann Womack   Country  2014-09-23 00:00:00   \n",
       "3                    Doris  Earl Sweatshirt       Rap  2013-08-20 00:00:00   \n",
       "4                  Giraffe          Echoboy      Rock  2003-02-25 00:00:00   \n",
       "\n",
       "       critic  score                                               body  \n",
       "0    Kerrang!   74.0  While For Baltimore proves they can still writ...  \n",
       "1       Uncut   70.0  There's nothing fake about the purgatorial nar...  \n",
       "2  Q Magazine   84.0  All life's disastrous lows are here on a caree...  \n",
       "3   Pitchfork   82.0  With Doris, Odd Future’s Odysseus is finally b...  \n",
       "4    AllMusic   71.0  Though Giraffe is definitely Echoboy's most im...  "
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews = pd.read_csv(music_fname, sep='\\t')\n",
    "reviews.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Print the text of the first review."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "While For Baltimore proves they can still write a grade A banger when they put their mind to it, too many songs are destined to have \"must try harder\" stamped on their report card. [13 Oct 2012, p.52]\n"
     ]
    }
   ],
   "source": [
    "print(reviews['body'][0])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Explore the Data using Pandas\n",
    "\n",
    "Let's first look at some descriptive statistics about this dataset, to get a feel for what's in it. We'll do this using the Pandas package. \n",
    "\n",
    "Note: this is always good practice. It serves two purposes. It checks to make sure your data is correct, and there's no major errors. It also keeps you in touch with your data, which will help with interpretation. <3 your data!\n",
    "\n",
    "First, what genres are in this dataset, and how many reviews in each genre?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Pop/Rock                  1486\n",
       "Indie                     1115\n",
       "Rock                       932\n",
       "Electronic                 513\n",
       "Rap                        363\n",
       "Pop                        149\n",
       "Country                    140\n",
       "R&B;                       112\n",
       "Folk                        70\n",
       "Alternative/Indie Rock      42\n",
       "Dance                       41\n",
       "Jazz                        38\n",
       "Name: genre, dtype: int64"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#We can count this using the value_counts() function\n",
    "reviews['genre'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The first thing most people do is to `describe` their data. (This is the `summary` command in R, or the `sum` command in Stata)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5001.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>72.684223</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>8.714896</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>7.400000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>68.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>74.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>79.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>100.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "             score\n",
       "count  5001.000000\n",
       "mean     72.684223\n",
       "std       8.714896\n",
       "min       7.400000\n",
       "25%      68.000000\n",
       "50%      74.000000\n",
       "75%      79.000000\n",
       "max     100.000000"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#There's only one numeric column in our data so we only get one column for output.\n",
    "reviews.describe()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This only gets us numerical summaries. To get summaries of some of the other columns, we can explicitly ask for it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>album</th>\n",
       "      <th>artist</th>\n",
       "      <th>genre</th>\n",
       "      <th>release_date</th>\n",
       "      <th>critic</th>\n",
       "      <th>body</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "      <td>5001</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>unique</th>\n",
       "      <td>3799</td>\n",
       "      <td>2607</td>\n",
       "      <td>12</td>\n",
       "      <td>956</td>\n",
       "      <td>592</td>\n",
       "      <td>4998</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>top</th>\n",
       "      <td>Sumday</td>\n",
       "      <td>Various Artists</td>\n",
       "      <td>Pop/Rock</td>\n",
       "      <td>2011-09-13 00:00:00</td>\n",
       "      <td>AllMusic</td>\n",
       "      <td>He does express regret about the marriage brea...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>freq</th>\n",
       "      <td>5</td>\n",
       "      <td>22</td>\n",
       "      <td>1486</td>\n",
       "      <td>29</td>\n",
       "      <td>282</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "         album           artist     genre         release_date    critic  \\\n",
       "count     5001             5001      5001                 5001      5001   \n",
       "unique    3799             2607        12                  956       592   \n",
       "top     Sumday  Various Artists  Pop/Rock  2011-09-13 00:00:00  AllMusic   \n",
       "freq         5               22      1486                   29       282   \n",
       "\n",
       "                                                     body  \n",
       "count                                                5001  \n",
       "unique                                               4998  \n",
       "top     He does express regret about the marriage brea...  \n",
       "freq                                                    2  "
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews.describe(include=['O'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Who were the reviewers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "AllMusic                     282\n",
       "PopMatters                   228\n",
       "Pitchfork                    207\n",
       "Q Magazine                   178\n",
       "Uncut                        171\n",
       "Mojo                         137\n",
       "Drowned In Sound             132\n",
       "New Musical Express (NME)    127\n",
       "The A.V. Club                121\n",
       "Rolling Stone                112\n",
       "Under The Radar              100\n",
       "Spin                          97\n",
       "The Guardian                  96\n",
       "musicOMH.com                  88\n",
       "Entertainment Weekly          87\n",
       "Slant Magazine                83\n",
       "Paste Magazine                72\n",
       "Consequence of Sound          69\n",
       "Alternative Press             69\n",
       "Prefix Magazine               68\n",
       "NOW Magazine                  66\n",
       "Tiny Mix Tapes                64\n",
       "Blender                       57\n",
       "Dusted Magazine               56\n",
       "Dot Music                     56\n",
       "Stylus Magazine               55\n",
       "No Ripcord                    53\n",
       "Boston Globe                  52\n",
       "Austin Chronicle              52\n",
       "Filter                        50\n",
       "                            ... \n",
       "bl_nk                          1\n",
       "marktron                       1\n",
       "TylerW                         1\n",
       "darkguyprime                   1\n",
       "InClass                        1\n",
       "DiscoStu                       1\n",
       "LanceA                         1\n",
       "BrandonS.                      1\n",
       "joyel1992                      1\n",
       "KrisB                          1\n",
       "RonR                           1\n",
       "federicobenny                  1\n",
       "matta                          1\n",
       "ImmersedInSound                1\n",
       "d                              1\n",
       "DustinT                        1\n",
       "KevinB                         1\n",
       "Ink Blot Magazine              1\n",
       "MegWhiteley                    1\n",
       "nathanm95                      1\n",
       "caseyk                         1\n",
       "Jai11elas                      1\n",
       "ElizabethM                     1\n",
       "BWETMatangi                    1\n",
       "Rustune                        1\n",
       "StellarSpine                   1\n",
       "NYCMark                        1\n",
       "sumac                          1\n",
       "Andresspagna                   1\n",
       "pertbanking                    1\n",
       "Name: critic, Length: 592, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['critic'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "And the artists?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Various Artists                  22\n",
       "R.E.M.                           16\n",
       "Arcade Fire                      14\n",
       "Sigur Rós                        13\n",
       "Belle & Sebastian                12\n",
       "Brian Eno                        11\n",
       "LCD Soundsystem                  10\n",
       "Weezer                           10\n",
       "Mogwai                           10\n",
       "Bob Dylan                        10\n",
       "Kings of Leon                    10\n",
       "Low                              10\n",
       "The Raveonettes                  10\n",
       "Radiohead                        10\n",
       "Sun Kil Moon                      9\n",
       "Wilco                             9\n",
       "Franz Ferdinand                   9\n",
       "Eels                              9\n",
       "M. Ward                           9\n",
       "Ghostface Killah                  9\n",
       "Los Campesinos!                   9\n",
       "Liars                             8\n",
       "Pearl Jam                         8\n",
       "Daft Punk                         8\n",
       "Elbow                             8\n",
       "Beck                              8\n",
       "The Roots                         8\n",
       "Kanye West                        8\n",
       "Modest Mouse                      8\n",
       "The Decemberists                  8\n",
       "                                 ..\n",
       "a-ha                              1\n",
       "Leaves                            1\n",
       "You Me at Six                     1\n",
       "Narrows                           1\n",
       "Young Smoke                       1\n",
       "Paloma Faith                      1\n",
       "Alanis Morissette                 1\n",
       "Rodion G.A.                       1\n",
       "White Whale                       1\n",
       "The Dear Hunter                   1\n",
       "Creepoid                          1\n",
       "Janet Jackson                     1\n",
       "Ariel Pink's Haunted Graffiti     1\n",
       "Charlotte Gainsbourg              1\n",
       "Numbers                           1\n",
       "The Bottle Rockets                1\n",
       "Little Jackie                     1\n",
       "Boats                             1\n",
       "Family of the Year                1\n",
       "Mara Carlyle                      1\n",
       "Sweet Billy Pilgrim               1\n",
       "Close                             1\n",
       "Portico Quartet                   1\n",
       "A Place to Bury Strangers         1\n",
       "Mathew Jonson                     1\n",
       "Oxford Collapse                   1\n",
       "Ima Robot                         1\n",
       "The Whigs                         1\n",
       "Angil & The Hidden Tracks         1\n",
       "The Go-Go's                       1\n",
       "Name: artist, Length: 2607, dtype: int64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['artist'].value_counts()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can get the average score as follows:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "72.68422315536893"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['score'].mean()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we want to know the average score for each genre? To do this, we use Pandas `groupby` function. You'll want to get very familiar with the `groupby` function. It's quite powerful."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "genre\n",
       "Jazz                      77.631579\n",
       "Folk                      75.900000\n",
       "Indie                     74.400897\n",
       "Country                   74.071429\n",
       "Alternative/Indie Rock    73.928571\n",
       "Electronic                73.140351\n",
       "Pop/Rock                  73.033782\n",
       "R&B;                      72.366071\n",
       "Rap                       72.173554\n",
       "Rock                      70.754292\n",
       "Dance                     70.146341\n",
       "Pop                       64.608054\n",
       "Name: score, dtype: float64"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews_grouped_by_genre = reviews.groupby(\"genre\")\n",
    "reviews_grouped_by_genre['score'].mean().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Creating the DTM using scikit-learn\n",
    "\n",
    "Ok, that's the summary of the metadata. Next, we turn to analyzing the text of the reviews. Remember, the text is stored in the 'body' column. First, a preprocessing step to remove numbers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "def remove_digits(comment):\n",
    "    return ''.join([ch for ch in comment if not ch.isdigit()])\n",
    "\n",
    "reviews['body_without_digits'] = reviews['body'].apply(remove_digits)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    While For Baltimore proves they can still writ...\n",
       "1    There's nothing fake about the purgatorial nar...\n",
       "2    All life's disastrous lows are here on a caree...\n",
       "3    With Doris, Odd Future’s Odysseus is finally b...\n",
       "4    Though Giraffe is definitely Echoboy's most im...\n",
       "Name: body_without_digits, dtype: object"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "reviews['body_without_digits'].head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### CountVectorizer Function\n",
    "\n",
    "Our next step is to turn the text into a document term matrix using the scikit-learn function called `CountVectorizer`. There are two ways to do this. We can turn it into a sparse matrix type, which can be used within `scikit-learn` for further analyses."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "#import the function CountVectorizer\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "\n",
    "countvec = CountVectorizer()\n",
    "\n",
    "sparse_dtm = countvec.fit_transform(reviews['body_without_digits'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Great! We made a DTM! Let's look at it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5001x16139 sparse matrix of type '<class 'numpy.int64'>'\n",
       "\twith 124340 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sparse_dtm"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This format is called Compressed Sparse Format. It save a lot of memory to store the dtm in this format, but it is difficult to look at for a human. To illustrate the techniques in this lesson we will first convert this matrix back to a Pandas DataFrame, a format we're more familiar with. For larger datasets, you will have to use the Compressed Sparse Format. Putting it into a DataFrame, however, will enable us to get more comfortable with Pandas!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooey</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zu</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>álbum</th>\n",
       "      <th>être</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "   aa  aaaa  aahs  aaliyah  aaron  ab  abandon  abandoned  abandoning  abc  \\\n",
       "0   0     0     0        0      0   0        0          0           0    0   \n",
       "1   0     0     0        0      0   0        0          0           0    0   \n",
       "2   0     0     0        0      0   0        0          0           0    0   \n",
       "3   0     0     0        0      0   0        0          0           0    0   \n",
       "4   0     0     0        0      0   0        0          0           0    0   \n",
       "\n",
       "   ...   zone  zones  zoo  zooey  zoomer  zu  zydeco  álbum  être  über  \n",
       "0  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "1  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "2  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "3  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "4  ...      0      0    0      0       0   0       0      0     0     0  \n",
       "\n",
       "[5 rows x 16139 columns]"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm = pd.DataFrame(sparse_dtm.toarray(), columns=countvec.get_feature_names(), index=reviews.index)\n",
    "dtm.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### What can we do with a DTM?\n",
    "\n",
    "We can quickly identify the most frequent words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the             7406\n",
       "and             4557\n",
       "of              4400\n",
       "to              3175\n",
       "is              2914\n",
       "it              2608\n",
       "that            2039\n",
       "in              1775\n",
       "album           1719\n",
       "this            1518\n",
       "but             1439\n",
       "with            1367\n",
       "as              1310\n",
       "on              1139\n",
       "for             1073\n",
       "are              812\n",
       "you              775\n",
       "their            775\n",
       "an               751\n",
       "his              743\n",
       "more             712\n",
       "be               691\n",
       "like             681\n",
       "from             676\n",
       "not              650\n",
       "songs            640\n",
       "one              580\n",
       "they             580\n",
       "its              575\n",
       "all              574\n",
       "                ... \n",
       "glimmering         1\n",
       "glimmers           1\n",
       "gliss              1\n",
       "glisten            1\n",
       "glistening         1\n",
       "glitch             1\n",
       "respond            1\n",
       "glitchier          1\n",
       "glitter            1\n",
       "glittering         1\n",
       "glittery           1\n",
       "glitz              1\n",
       "glo                1\n",
       "gloating           1\n",
       "respectively       1\n",
       "globular           1\n",
       "respectfully       1\n",
       "gloria             1\n",
       "glories            1\n",
       "gloriously         1\n",
       "glossily           1\n",
       "resorting          1\n",
       "glowering          1\n",
       "glowin             1\n",
       "glowing            1\n",
       "glows              1\n",
       "glue               1\n",
       "gluttonously       1\n",
       "glyn               1\n",
       "sincerest          1\n",
       "Length: 16139, dtype: int64"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.sum().sort_values(ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Print out the most infrequent words rather than the most frequent words. You can look at the [Pandas documentation](http://pandas.pydata.org/pandas-docs/stable/api.html#api-dataframe-stats) for more information.\n",
    "\n",
    "### Gold star challenge: \n",
    "* Print the average number of times each word is used in a review.\n",
    "* Print this out sorted from lowest to highest."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "sincerest       1\n",
       "glyn            1\n",
       "gluttonously    1\n",
       "glue            1\n",
       "glows           1\n",
       "dtype: int64"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.sum().sort_values().head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "the    1.480904\n",
       "and    0.911218\n",
       "of     0.879824\n",
       "to     0.634873\n",
       "is     0.582683\n",
       "dtype: float64"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dtm.mean().sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF scores\n",
    "\n",
    "How to find distinctive words in a corpus is a long-standing question in text analysis? Today, we'll learn one simple approach to this: TF-IDF. The idea behind words scores is to weight words not just by their frequency, but by their frequency in one document compared to their distribution across all documents. Words that are frequent, but are also used in every single document, will not be distinguising. We want to identify words that are unevenly distributed across the corpus.\n",
    "\n",
    "One of the most popular ways to weight words (beyond frequency counts) is `tf-idf score`. By offsetting the frequency of a word by its document frequency (the number of documents in which it appears) will in theory filter out common terms such as 'the', 'of', and 'and'.\n",
    "\n",
    "Traditionally, the inverse document frequency is calculated as such:\n",
    "\n",
    "number_of_documents / number_documents_with_term\n",
    "\n",
    "so:\n",
    "\n",
    "tfidf_word1 = word1_frequency_document1 * (number_of_documents / number_document_with_word1)\n",
    "\n",
    "You can, and often should, normalize the numerator: \n",
    "\n",
    "tfidf_word1 = (word1_frequency_document1 / word_count_document1) * (number_of_documents / number_document_with_word1)\n",
    "\n",
    "We can calculate this manually, but scikit-learn has a built-in function to do so. This function also uses log frequencies, so the numbers will not correspond excactly to the calculations above. We'll use the [scikit-learn calculation](http://scikit-learn.org/stable/modules/generated/sklearn.feature_extraction.text.TfidfVectorizer.html), but a challenge for you: use Pandas to calculate this manually. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDFVectorizer Function\n",
    "\n",
    "To do so, we simply do the same thing we did above with CountVectorizer, but instead we use the function TfidfVectorizer."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<5001x16139 sparse matrix of type '<class 'numpy.float64'>'\n",
       "\twith 124340 stored elements in Compressed Sparse Row format>"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "\n",
    "tfidfvec = TfidfVectorizer()\n",
    "sparse_tfidf = tfidfvec.fit_transform(reviews['body_without_digits'])\n",
    "sparse_tfidf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zone</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooey</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zu</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>álbum</th>\n",
       "      <th>être</th>\n",
       "      <th>über</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16139 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaaa  aahs  aaliyah  aaron   ab  abandon  abandoned  abandoning  abc  \\\n",
       "0  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "1  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "2  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "3  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "4  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "\n",
       "   ...   zone  zones  zoo  zooey  zoomer   zu  zydeco  álbum  être  über  \n",
       "0  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "1  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "2  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "3  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "4  ...    0.0    0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0  \n",
       "\n",
       "[5 rows x 16139 columns]"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf = pd.DataFrame(sparse_tfidf.toarray(), columns=tfidfvec.get_feature_names(), index=reviews.index)\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's look at the 20 words with highest tf-idf weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "brill         1.000000\n",
       "perfect       1.000000\n",
       "yummy         1.000000\n",
       "pppperfect    1.000000\n",
       "awesome       1.000000\n",
       "wonderfull    1.000000\n",
       "meh           1.000000\n",
       "stars         1.000000\n",
       "subpar        0.959257\n",
       "ga            0.908259\n",
       "masterful     0.898620\n",
       "grower        0.888624\n",
       "likable       0.867803\n",
       "acirc         0.867003\n",
       "great         0.864253\n",
       "infectious    0.859996\n",
       "blank         0.854475\n",
       "thrilling     0.848810\n",
       "smart         0.847852\n",
       "stuff         0.834479\n",
       "dtype: float64"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf.max().sort_values(ascending=False).head(20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ok! We have successfully identified content words, without removing stop words. What else do you notice about this list?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Identifying Distinctive Words\n",
    "\n",
    "What can we do with this? These scores are best used when you want to identify distinctive words for individual documents, or groups of documents, compared to other groups or the corpus as a whole. To illustrate this, let's compare three genres and identify the most distinctive words by genre.\n",
    "\n",
    "First we add in a column of genre."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>aa</th>\n",
       "      <th>aaaa</th>\n",
       "      <th>aahs</th>\n",
       "      <th>aaliyah</th>\n",
       "      <th>aaron</th>\n",
       "      <th>ab</th>\n",
       "      <th>abandon</th>\n",
       "      <th>abandoned</th>\n",
       "      <th>abandoning</th>\n",
       "      <th>abc</th>\n",
       "      <th>...</th>\n",
       "      <th>zones</th>\n",
       "      <th>zoo</th>\n",
       "      <th>zooey</th>\n",
       "      <th>zoomer</th>\n",
       "      <th>zu</th>\n",
       "      <th>zydeco</th>\n",
       "      <th>álbum</th>\n",
       "      <th>être</th>\n",
       "      <th>über</th>\n",
       "      <th>genre_</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Pop/Rock</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Country</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rap</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>...</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>0.0</td>\n",
       "      <td>Rock</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 16140 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "    aa  aaaa  aahs  aaliyah  aaron   ab  abandon  abandoned  abandoning  abc  \\\n",
       "0  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "1  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "2  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "3  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "4  0.0   0.0   0.0      0.0    0.0  0.0      0.0        0.0         0.0  0.0   \n",
       "\n",
       "     ...     zones  zoo  zooey  zoomer   zu  zydeco  álbum  être  über  \\\n",
       "0    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "1    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "2    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "3    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "4    ...       0.0  0.0    0.0     0.0  0.0     0.0    0.0   0.0   0.0   \n",
       "\n",
       "     genre_  \n",
       "0  Pop/Rock  \n",
       "1   Country  \n",
       "2   Country  \n",
       "3       Rap  \n",
       "4      Rock  \n",
       "\n",
       "[5 rows x 16140 columns]"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tfidf['genre_'] = reviews['genre']\n",
    "tfidf.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now lets compare the words with the highest tf-idf weight for each genre. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "blank        0.854475\n",
       "waste        0.755918\n",
       "amiable      0.730963\n",
       "awesomely    0.717079\n",
       "joyless      0.687687\n",
       "dtype: float64"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "rap = tfidf[tfidf['genre_']=='Rap']\n",
    "indie = tfidf[tfidf['genre_']=='Indie']\n",
    "jazz = tfidf[tfidf['genre_']=='Jazz']\n",
    "\n",
    "rap.max(numeric_only=True).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "meh           1.0\n",
       "wonderfull    1.0\n",
       "yummy         1.0\n",
       "pppperfect    1.0\n",
       "perfect       1.0\n",
       "dtype: float64"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "indie.max(numeric_only=True).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "purely        0.544477\n",
       "descending    0.519218\n",
       "devotional    0.507724\n",
       "recordings    0.499963\n",
       "languid       0.487715\n",
       "dtype: float64"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "jazz.max(numeric_only=True).sort_values(ascending=False).head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "There we go! A method of identifying distinctive words. You notice there are some proper nouns in there. How might we remove those if we're not interested in them?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Challenge\n",
    "\n",
    "Instead of outputting the highest weighted words, output the lowest weighted words. How should we interpret these words?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Topic modeling <a id='topics'></a>\n",
    "\n",
    "There are many topic modeling algorithms, but we'll use LDA. This is a standard model to use. Again, the goal is not to learn everything you need to know about topic modeling. Instead, this will provide you some starter code to run a simple model, with the idea that you can use this base of knowledge to explore this further.\n",
    "\n",
    "We will run Latent Dirichlet Allocation, the most basic and the oldest version of topic modeling. We will run this in one big chunk of code. Our challenge: use our knowledge of scikit-learn that we gained aboe to walk through the code to understand what it is doing. Your challenge: figure out how to modify this code to work on your own data, and/or tweak the parameters to get better output.\n",
    "\n",
    "Note: we will be using a different dataset for this technique. The music reviews in the above dataset are often short, one word or one sentence reviews. Topic modeling is not really appropriate for texts that are this short. Instead, we want texts that are longer and are composed of multiple topics each. For this exercise we will use a database of children's literature from the 19th century. \n",
    "\n",
    "The data were compiled by students in this course: http://english197s2015.pbworks.com/w/page/93127947/FrontPage\n",
    "Found here: http://dhresourcesforprojectbuilding.pbworks.com/w/page/69244469/Data%20Collections%20and%20Datasets#demo-corpora\n",
    "\n",
    "That page has additional corpora, for those interested in exploring text analysis further.\n",
    "\n",
    "I did some minimal cleaning to get the children's literature data in .csv format for our use."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>title</th>\n",
       "      <th>author gender</th>\n",
       "      <th>year</th>\n",
       "      <th>text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>A Dog with a Bad Name</td>\n",
       "      <td>Male</td>\n",
       "      <td>1886</td>\n",
       "      <td>A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>A Final Reckoning</td>\n",
       "      <td>Male</td>\n",
       "      <td>1887</td>\n",
       "      <td>A Final Reckoning: A Tale of Bush Life in Aust...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>A House Party, Don Gesualdo, and A Rainy June</td>\n",
       "      <td>Female</td>\n",
       "      <td>1887</td>\n",
       "      <td>A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>A Houseful of Girls</td>\n",
       "      <td>Female</td>\n",
       "      <td>1889</td>\n",
       "      <td>A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>A Little Country Girl</td>\n",
       "      <td>Female</td>\n",
       "      <td>1885</td>\n",
       "      <td>LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                           title author gender  year  \\\n",
       "0                          A Dog with a Bad Name          Male  1886   \n",
       "1                              A Final Reckoning          Male  1887   \n",
       "2  A House Party, Don Gesualdo, and A Rainy June        Female  1887   \n",
       "3                            A Houseful of Girls        Female  1889   \n",
       "4                          A Little Country Girl        Female  1885   \n",
       "\n",
       "                                                text  \n",
       "0  A DOG WITH A BAD NAME  BY TALBOT BAINES REED  ...  \n",
       "1  A Final Reckoning: A Tale of Bush Life in Aust...  \n",
       "2  A HOUSE-PARTY  Don Gesualdo  and  A Rainy June...  \n",
       "3  A HOUSEFUL OF GIRLS. BY SARAH TYTLER,  AUTHOR ...  \n",
       "4  LITTLE COUNTRY GIRL.  BY  SUSAN COOLIDGE,     ...  "
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "literature_fname = os.path.join(DATA_DIR, 'childrens_lit.csv.bz2')\n",
    "df_lit = pd.read_csv(literature_fname, sep='\\t', encoding = 'utf-8', compression = 'bz2', index_col=0)\n",
    "\n",
    "#drop rows where the text is missing\n",
    "df_lit = df_lit.dropna(subset=['text'])\n",
    "df_lit.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we're ready to fit the model. This requires the use of CountVecorizer, which we've already used, and the scikit-learn function LatentDirichletAllocation.\n",
    "\n",
    "See [here](http://scikit-learn.org/stable/modules/generated/sklearn.decomposition.LatentDirichletAllocation.html) for more information about this function. \n",
    "\n",
    "First, we have to import it from sklearn. We tell the model how many topics we expect to find."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import LatentDirichletAllocation\n",
    "n_topics = 5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In sklearn, the input to LDA is a DTM (with either counts or TF-IDF scores)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [],
   "source": [
    "tfidf_vectorizer = TfidfVectorizer(max_df=0.80, min_df=50,\n",
    "                                   max_features=None,\n",
    "                                   stop_words='english')\n",
    "tfidf = tfidf_vectorizer.fit_transform(df_lit['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [],
   "source": [
    "tf_vectorizer = CountVectorizer(max_df=0.80, min_df=50,\n",
    "                                max_features=None,\n",
    "                                stop_words='english'\n",
    "                                )\n",
    "tf = tf_vectorizer.fit_transform(df_lit['text'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This is where we fit the model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/Users/bacon/anaconda3/lib/python3.6/site-packages/sklearn/decomposition/online_lda.py:536: DeprecationWarning: The default value for 'learning_method' will be changed from 'online' to 'batch' in the release 0.20. This warning was introduced in 0.18.\n",
      "  DeprecationWarning)\n"
     ]
    }
   ],
   "source": [
    "lda = LatentDirichletAllocation(n_components=n_topics, max_iter=20, random_state=0)\n",
    "lda = lda.fit(tf)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [],
   "source": [
    "##This is a function to print out the top words for each topic in a pretty way.\n",
    "#Don't worry too much about understanding every line of this code.\n",
    "def print_top_words(model, feature_names, n_top_words):\n",
    "    for topic_idx, topic in enumerate(model.components_):\n",
    "        print(\"\\nTopic #%d:\" % topic_idx)\n",
    "        print(\" \".join([feature_names[i]\n",
    "                        for i in topic.argsort()[:-n_top_words - 1:-1]]))\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Topic #0:\n",
      "doctor girls papa mamma sister baby street aunt london dr tom sweet tea study presently flower cousin darling wasn everybody\n",
      "\n",
      "Topic #1:\n",
      "dick uncle doctor jack er tom ain den yer fish em lads rock rope gun wolf birds beneath stream ay\n",
      "\n",
      "Topic #2:\n",
      "king camp prince indian queen tom mountain snow ice ha hut rock arrows band palace forest village savage observed ship\n",
      "\n",
      "Topic #3:\n",
      "project ye works deck ship shore foundation george vessel island lake em agreement states mate public cabin fish boats doctor\n",
      "\n",
      "Topic #4:\n",
      "king army french troops attack officers john soldiers ship camp officer frank city village guns regiment march rode prince jack\n",
      "\n"
     ]
    }
   ],
   "source": [
    "tf_feature_names = tf_vectorizer.get_feature_names()\n",
    "print_top_words(lda, tf_feature_names, 20)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Further resources\n",
    "\n",
    "[This blog post](https://de.dariah.eu/tatom/feature_selection.html) goes through finding distinctive words using Python in more detail \n",
    "\n",
    "Paper: [Fightin’ Words: Lexical Feature Selection and Evaluation for Identifying the Content of Political Conflict](http://languagelog.ldc.upenn.edu/myl/Monroe.pdf), Burt Monroe, Michael Colaresi, Kevin Quinn\n",
    "\n",
    "[More detailed description of implementing LDA using scikit-learn](http://scikit-learn.org/stable/auto_examples/applications/topics_extraction_with_nmf_lda.html#sphx-glr-auto-examples-applications-topics-extraction-with-nmf-lda-py).\n",
    "\n",
    "[Topic modeling with Textacy](https://github.com/repmax/topic-model/blob/master/topic-modelling.ipynb)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
